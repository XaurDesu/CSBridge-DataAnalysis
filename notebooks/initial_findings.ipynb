{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#we import sys to add the models folder to path, allowing us to use those scripts in visualization\n",
    "import sys\n",
    "sys.path.insert(1, '../models/')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import clean_data as cd\n",
    "\n",
    "from math import pi\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.plotting import figure, show\n",
    "from fractions import Fraction\n",
    "\n",
    "\n",
    "\n",
    "pn.extension('tabulator')\n",
    "\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Data Management--\n",
    "Now, we get the .csv files with raw data from the '/data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/all_sections.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--File Reading--\n",
    "\n",
    "We're now going to read the files that we got beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...And now we'll call the data cleaning scripts on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We rename the columns to make them easier to work with\n",
    "data.rename(columns={\n",
    "    #WEEK 1\n",
    "    'OrgDefinedId':'user',\n",
    "    'Secciones':'sec',\n",
    "    'Entrega de la mañana D1 Points Grade <Numérico Puntos máx.:5 Categoría:Semana 1\\Week1>':'1AM',\n",
    "    'Entrega de la tarde D1 Points Grade <Numérico Puntos máx.:5 Categoría:Semana 1\\Week1>':'1PM',\n",
    "    'Entrega de la mañana (D2) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 1\\Week1>':'2AM',\n",
    "    'Entrega de la tarde (D2) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 1\\Week1>':'2PM',\n",
    "    'Entrega de la mañana (D3) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 1\\Week1>':'3AM',\n",
    "    'Entrega de la tarde (D3) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 1\\Week1>':'3PM',\n",
    "    'Entrega de la mañana (D4) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 1\\Week1>':'4AM',\n",
    "    'Entrega de la tarde (D4) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 1\\Week1>':'4PM',\n",
    "\n",
    "    'Semana 1\\Week1 Subtotal Numerator':'week_1_numerator',\n",
    "    'Semana 1\\Week1 Subtotal Denominator':'week_1_denominator',\n",
    "    \n",
    "    #WEEK 2\n",
    "    'Entrega de la tarde (D5) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 2\\Week 2>':'5PM',\n",
    "    'Entrega de la mañana (D5) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 2\\Week 2>':'5AM',\n",
    "    'Entrega de la mañana (D6) Points Grade <Numérico Puntos máx.:5 Categoría:Semana 2\\Week 2>':'6AM',\n",
    "\n",
    "    'Semana 2\\Week 2 Subtotal Numerator':'week_2_numerator',\n",
    "    'Semana 2\\Week 2 Subtotal Denominator':'week_2_denominator',\n",
    "\n",
    "    'Calculated Final Grade Numerator':'final_numerator',\n",
    "    'Calculated Final Grade Denominator':'final_denominator'\n",
    "}, inplace = True)\n",
    "\n",
    "#drop unnecesary columns\n",
    "data.drop(columns={'Adjusted Final Grade Numerator', 'Adjusted Final Grade Denominator','End-of-Line Indicator'}, axis=1, inplace=True)\n",
    "#filter blank students\n",
    "data = data[data['sec'].notna()]\n",
    "#fill NaN with 0\n",
    "data.fillna(0.0, inplace=True)\n",
    "\n",
    "#change sections to numbers, this will be useful for binding on analytic tables later\n",
    "data['sec'].replace(['Sección No. 1', 'Sección No. 2', 'Sección No. 3','Sección No. 4','Sección No. 5','Sección No. 6','Sección No. 7',\n",
    "'Sección No. 8','Sección No. 9','Sección No. 10 - Las morcillitas'], [1,2,3,4,5,6,7,8,9,10], inplace=True)\n",
    "\n",
    "#we change the type to a numeric float64 from 'object'\n",
    "#Week 1\n",
    "data['1AM'] = pd.to_numeric(data['1AM'])\n",
    "data['1PM'] = pd.to_numeric(data['1PM'])\n",
    "data['2AM'] = pd.to_numeric(data['2AM'])\n",
    "data['2PM'] = pd.to_numeric(data['2PM'])\n",
    "data['3AM'] = pd.to_numeric(data['3AM'])\n",
    "data['3PM'] = pd.to_numeric(data['3PM'])\n",
    "data['4AM'] = pd.to_numeric(data['4AM'])\n",
    "data['4PM'] = pd.to_numeric(data['4PM'])\n",
    "#Week 2\n",
    "data['5AM'] = pd.to_numeric(data['5AM'])\n",
    "data['5PM'] = pd.to_numeric(data['5PM'])\n",
    "data['6AM'] = pd.to_numeric(data['6AM'])\n",
    "\n",
    "\n",
    "#we recalculate the numerator and denominator for every student, as the data didn't take NaN into account.\n",
    "for index in data.index:\n",
    "        #week 1\n",
    "        a = (sum([data.loc[index, '1AM'],\n",
    "        data.loc[index, '1PM'],\n",
    "        data.loc[index, '2AM'],\n",
    "        data.loc[index, '2PM'],\n",
    "        data.loc[index, '3AM'],\n",
    "        data.loc[index, '3PM'],\n",
    "        data.loc[index, '4AM'],\n",
    "        data.loc[index, '4PM']]))\n",
    "        b = 8.0\n",
    "\n",
    "        data.loc[index, 'week_1_numerator'] = Fraction(a/b).numerator\n",
    "        data.loc[index, 'week_1_denominator'] = Fraction(a/b).denominator\n",
    "\n",
    "        #week 2\n",
    "        a = (sum([data.loc[index, '5AM'],\n",
    "                data.loc[index, '5PM'],\n",
    "                data.loc[index, '6AM']]))\n",
    "        b = 3.0\n",
    "\n",
    "        data.loc[index, 'week_2_numerator'] = Fraction(a/b).numerator\n",
    "        data.loc[index, 'week_2_denominator'] = Fraction(a/b).denominator\n",
    "\n",
    "        #final values, this operation might come as redundant at first, but it is quite important for final averages. Either way, i might \n",
    "        #optimize it in the future.\n",
    "        a = (sum([data.loc[index, '1AM'],\n",
    "        data.loc[index, '1PM'],\n",
    "        data.loc[index, '2AM'],\n",
    "        data.loc[index, '2PM'],\n",
    "        data.loc[index, '3AM'],\n",
    "        data.loc[index, '3PM'],\n",
    "        data.loc[index, '4AM'],\n",
    "        data.loc[index, '4PM'],\n",
    "        data.loc[index, '5AM'],\n",
    "        data.loc[index, '5PM'],\n",
    "        data.loc[index, '6AM']]))\n",
    "        b = 11.0\n",
    "        \n",
    "        data.loc[index, 'week_2_numerator'] = Fraction(a/b).numerator\n",
    "        data.loc[index, 'week_2_denominator'] = Fraction(a/b).denominator\n",
    "\n",
    "\n",
    "interactive_data = data.interactive()\n",
    "data    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all of that is said and done, it's time to start making some graphs from this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average notes by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Day 1','Day 2','Day 3','Day 4','Day 5','Day 6']\n",
    "\n",
    "day_averages = [(data['1AM'].sum()+data['1PM'].sum())/(len(data)*2),\n",
    "(data['2AM'].sum()+data['2PM'].sum())/(len(data)*2),\n",
    "(data['3AM'].sum()+data['3PM'].sum())/(len(data)*2),\n",
    "(data['4AM'].sum()+data['4PM'].sum())/(len(data)*2),\n",
    "(data['5AM'].sum()+data['5PM'].sum())/(len(data)*2),\n",
    "data['6AM'].sum()/(len(data))]\n",
    "\n",
    "\n",
    "avg_day_notes_source = ColumnDataSource(data=dict(days = days, day_averages = day_averages, color = Spectral6))\n",
    "day_notes_figure = figure(x_range = days, y_range=(0,5), height=400, title=\"Average notes per day\",toolbar_location=None, tools=\"\")\n",
    "day_notes_figure.vbar(x='days', top='day_averages', width=0.9, color='color', legend_field=\"days\", source=avg_day_notes_source)\n",
    "\n",
    "day_notes_figure.xgrid.grid_line_color = None\n",
    "day_notes_figure.legend.orientation = \"horizontal\"\n",
    "day_notes_figure.legend.location = \"top_center\"\n",
    "\n",
    "show(day_notes_figure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of notes by ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_ranges = {\n",
    "    '5: Perfect implementation.':0,\n",
    "    '3.5 - 4.9: Functional implementation with small problems.':0,\n",
    "    '0.1 - 3.4: Implementation with serious problems (not working)':0,\n",
    "    \"0: Did not submit the work.\": 0\n",
    "}\n",
    "concept_checks = ['1AM','1PM','2AM','2PM','3AM','3PM','4AM','4PM','5AM','5PM','6AM'] \n",
    "\n",
    "for index in data.index:\n",
    "    for concept in concept_checks:\n",
    "        grade = data.loc[index, concept]\n",
    "        if grade == 0:\n",
    "            note_ranges[\"0: Did not submit the work.\"] += 1\n",
    "        elif grade == 5:\n",
    "            note_ranges['5: Perfect implementation.'] += 1\n",
    "        elif grade in np.arange(3.5, 5):\n",
    "            note_ranges['3.5 - 4.9: Functional implementation with small problems.'] += 1\n",
    "        else:\n",
    "            note_ranges['0.1 - 3.4: Implementation with serious problems (not working)'] += 1\n",
    "\n",
    "note_dist_data = pd.Series(note_ranges).reset_index(name='value').rename(columns={'index': 'range'})\n",
    "note_dist_data['angle'] = note_dist_data['value']/note_dist_data['value'].sum() * 2*pi\n",
    "note_dist_data['color'] = Category20c[len(note_ranges)]\n",
    "\n",
    "pie_chart = figure(height=400, title=\"Distribution of notes by ranges\", toolbar_location=None,\n",
    "           tools=\"hover\", tooltips=\"@range: @value\", x_range=(-0.5, 1.0))\n",
    "\n",
    "pie_chart.wedge(x=0, y=1, radius=0.4,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", fill_color='color', legend_field='range', source=note_dist_data)\n",
    "\n",
    "show(pie_chart)\n",
    "print(note_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final note curve graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Server Display Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layout using Template\n",
    "template = pn.template.FastListTemplate(\n",
    "    title='CS Bridge - Initial Findings',\n",
    "    sidebar=[pn.pane.Markdown(\"CS Bridge -Uniandes\")\n",
    "    \n",
    "    ], \n",
    "    main=[pn.Column(pn.Row(pn.pane.Bokeh(pie_chart),pn.pane.Bokeh(day_notes_figure))), \n",
    "        pn.Column(pn.Row())],\n",
    "    accent_base_color=\"#2f3e46\",\n",
    "    header_background=\"#354f52\",\n",
    ")\n",
    "template.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
